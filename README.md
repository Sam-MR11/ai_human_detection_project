# ğŸ¤– AI vs Human Text Detection

A machine learning-powered web application built with Streamlit to detect whether text was written by a human or generated by an AI (e.g., ChatGPT). Upload `.txt`, `.docx`, or `.pdf` files, or type text directly. Choose a classification model (SVM, Decision Tree, AdaBoost), and receive real-time predictions with confidence scores and visual explanations.

-----------------------------------------------------------------------------------------------------------------------------------------------------

## ğŸ“ Project Structure
```
ai_human_detection_project/
â”œâ”€â”€ app.py # ğŸš€ Main Streamlit application
â”œâ”€â”€ requirements.txt # ğŸ“¦ Project dependencies
â”œâ”€â”€ models/ # ğŸ” Trained ML models and vectorizer
â”‚ â”œâ”€â”€ Human_Vs_AI_Written_pipeline.pkl
â”‚ â”œâ”€â”€ optimized_svm_model.pkl
â”‚ â”œâ”€â”€ decision_tree_pipeline.pkl
â”‚ â”œâ”€â”€ adaboost_pipeline.pkl
| â”œâ”€â”€ feature_selector.pkl
| â”œâ”€â”€ individual_svm_classifier.pkl
| â”œâ”€â”€ optimized_adaboost_model.pkl
| â”œâ”€â”€ optimized_dt_model.pkl
| â”œâ”€â”€ sol2_pipeline_tfidf_vectorizer.pkl
â”‚ â””â”€â”€ tfidf_vectorizer.pkl
â”œâ”€â”€ data/ # ğŸ§ª Raw and test datasets
â”‚ â”œâ”€â”€ AI_vs_huam_train_dataset/
â”‚ â””â”€â”€ Final_test_data/
â”œâ”€â”€ notebooks/ # ğŸ““ Jupyter notebooks (model training & analysis)
â”‚ â””â”€â”€ Project_1.ipynb
â”œâ”€â”€ sample_files/ # ğŸ“ Test documents (.txt, .pdf, .docx)
â”‚ â”œâ”€â”€ AI Generated.txt
â”‚ â”œâ”€â”€ AI Generated.pdf
â”‚ â””â”€â”€ Human-Written.docx
â””â”€â”€ README.md # ğŸ“˜ Project documentation
```
----------------------------------------------------------------------------------------------------------------------------------------------------

## ğŸ’¡ Project Features

- ğŸ§  Trained and tuned 3 classifiers (SVM, Decision Tree, AdaBoost)
- ğŸ” Supports `.txt`, `.docx`, and `.pdf` input formats
- ğŸ“Š Displays prediction probabilities and agreement analysis
- ğŸ“ˆ Real-time visualizations (confidence, model comparison, word stats)
- ğŸ’¾ Option to download prediction reports
- ğŸ“ Uses TF-IDF vectorization with optimized linguistic features
- ğŸ“ Clean and modular ML pipeline

----------------------------------------------------------------------------------------------------------------------------------------------------

## ğŸ”§ Installation Instructions

#### 1. Clone the repository

```bash
git clone https://github.com/Sam120-ass/ai_human_detection_project.git
cd ai_human_detection_project
```

#### 2. Create Virtual Environment
```bash
python -m venv venv        #"venv venv" or 'create a folder': Eg: python -m venv project1 (Creates a project1 folder)
source venv/bin/activate    # On Windows: venv\Scripts\activate
```

#### 3. Install the dependencies
```bash
pip install -r requirements.txt
```

Open VS Code/IDE

### Running the Streamlit App

```bash
streamlit run app.py
```

This will launch a local web server where you can:

- Upload text files (.txt, .docx, .pdf)
- Choose from the 3 classifiers (SVM, Decision Tree, AdaBoost)
- View AI vs Human predictions with confidence scores
- See visualizations and model comparison
- Download prediction reports

### Machine Learning Models

All models were trained using optimized parameters with GridSearchCV and evaluated using 5-fold stratified cross-validation.
```
Model	                  Accuracy	                Features Used	          Notes
SVM		                      >90%              TF-IDF(10,000 ngrams)       Best overall performance
Decision Tree			      ~75%                      TF-IDF (2000)       Fast and interpretable
AdaBoost			          ~82%                      TF-IDF (2000)       Robust to noise, ensemble-based
```
The models and the vectorizer are saved in the models/ folder using joblib.


### Input File Support
The app supports:

- Plain Text Files: .txt
- Word Documents: .docx (via python-docx)
- PDF Files: .pdf (via pdfplumber)

### Dependencies
Minimal versions used in training:
```txt
pandas>=2.0.0
numpy>=1.26.0
scikit-learn>=1.4.0
matplotlib>=3.7.1
seaborn>=0.12.2
plotly>=5.15.0
joblib>=1.3.2
nltk
pdfplumber
python-docx
fpdf
streamlit
wordcloud
```


INSTALL ALL USING:
```bash
pip install -r requirements.txt
```
----------------------------------------------------------------------------------------------------------------------------------------------------

### ğŸ“Š Visualisations Included 

    - Prediction probability bars

    - Model agreement/disagreement summary

    - Word frequency cloud

    - Feature importance (for tree-based models)

    - Word count/sentence length stats

### ğŸ“ Models Directory (/models)

Ensure these files are present in the /models folder before running the app:

    - Human_Vs_AI_Written_pipeline.pkl
    - decision_tree_pipeline.pkl
    - adaboost_pipeline.pkl
    - tfidf_vectorizer.pkl

### ğŸ“‹ Report and Evaluation Highlights
    
    - Accuracy, Precision, Recall, F1-score reported

    - Confusion matrices & ROC curves plotted for all models

    - Agreement rates between models calculated and visualized

    - Final model selected based on best cross-validation and holdout performance

### ğŸ§ª Testing Files

Located in sample_files/:
    
    - AI Generated.txt

    - Human-Written.docx

    - AI Generated.pdf

Use these for demo and testing the app UI.

### ğŸ›  Design Decisions & Notes

ğŸ§© Used Pipeline() to combine preprocessing, TF-IDF, and classifier into one object

âœ… Ensured consistency by not mixing custom and pipeline preprocessing

ğŸ§ª All models were trained using the same TF-IDF vectorizer (2000/10000 features depending on model)

ğŸ“ Saved modular models for better control and debugging


### ğŸ“½ Demo Video (to be added)

A demo video is added here showing:

  - Model selection and predictions

  - Uploading PDF/Word/Text documents

  - Agreement analysis and downloading reports

## ğŸ‘¨â€ğŸ’» Contributors

  - Samaya Niraula - https://github.com/Sam120-ass

## ğŸ“œ License

This project is licensed for educational use.

## ğŸ™‹â€â™€ï¸ Questions?

Feel free to raise an Issue on the GitHub repo or contact the developer.

----------------------------------------------------------------------------------------------------------------------------------------------------

